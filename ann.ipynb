{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pkbar\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self,tensor):\n",
    "        self.weights = tensor \n",
    "        self.gradients = np.zeros_like(self.weights)\n",
    "        self.bias = np.zeros((tensor.shape[-1]))\n",
    "        self.bias_gradients = np.zeros_like(self.bias)\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.parameters = None \n",
    "    def init_param(self, tensor):\n",
    "        param = Parameter(tensor)\n",
    "        self.parameters = param \n",
    "        return param \n",
    "    def update(self, optimizer):\n",
    "        optimizer.update(self.parameters)\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self,lr=0.1):\n",
    "        self.lr = lr \n",
    "    def update(self,param):\n",
    "        param.weights -= self.lr * param.gradients\n",
    "        param.bias -= self.lr * param.bias\n",
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        self.parameters = None \n",
    "\n",
    "    def backward(self,D,X):\n",
    "        S = 1 / (1+np.exp(-X))\n",
    "        return D * (S*(1-S))\n",
    "    def forward(self,X):\n",
    "        return 1/(1+np.exp(-X))\n",
    "    def __str__(self) -> str:\n",
    "        return \"Sigmoid Layer\"\n",
    "class Softmax(Layer):\n",
    "    def __init__(self):\n",
    "        self.parameters = None \n",
    "    def backward(self,D,X):\n",
    "        return D \n",
    "    def softmax(self,X):\n",
    "        k = np.sum(np.exp(X),axis=-1).reshape(-1,1)\n",
    "        return np.exp(X) / k\n",
    "    def forward(self,X):\n",
    "        return self.softmax(X)\n",
    "    def __str__(self) -> str:\n",
    "        return \"Softmax Layer\"\n",
    "class Tanh(Layer):\n",
    "    def __init__(self):\n",
    "        self.parameters = None \n",
    "    def backward(self,D,X):\n",
    "        return D * (1-(np.tanh(X)*np.tanh(X)))\n",
    "    def forward(self,X):\n",
    "        return np.tanh(X)\n",
    "    def __str__(self) -> str:\n",
    "        return \"Tanh Layer\"\n",
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        self.parameters = None \n",
    "    def backward(self, D,X):\n",
    "        return D * (1*(X>0))\n",
    "    def forward(self,X):\n",
    "        return np.maximum(0,X)\n",
    "    def __str__(self) -> str:\n",
    "        return \"ReLU Layer\"\n",
    "class Linear(Layer):\n",
    "    '''\n",
    "    Linear layer\n",
    "    '''\n",
    "    def __init__(self,inputs,outputs) -> None:\n",
    "        super().__init__()\n",
    "        tensor = np.random.randn(inputs,outputs)\n",
    "        self.parametres = self.init_param(tensor)\n",
    "    def backward(self, D,X):\n",
    "        self.parametres.gradients = (X.T@ D)\n",
    "        X_bias = np.ones(X.shape[0])\n",
    "        self.parametres.bias_gradients = X_bias.T@D \n",
    "        # D * w.T\n",
    "        return D @ self.parametres.weights.T\n",
    "    def forward(self, X):\n",
    "        # X*w * b\n",
    "        return X@self.parametres.weights + self.parametres.bias\n",
    "    def __str__(self) -> str:\n",
    "        return \"Linear Layer\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.computational_graph = []\n",
    "    def add(self,layer):\n",
    "        self.computational_graph.append(layer)\n",
    "    def compiler(self,loss,optimizer):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer \n",
    "    def forward(self,X):\n",
    "        Y_int = X \n",
    "        Y_int_list = [] \n",
    "        for layer in self.computational_graph:\n",
    "            Y_int_list.append(Y_int)\n",
    "            Y_ = layer.forward(Y_int)\n",
    "            Y_int = Y_ \n",
    "        return Y_, Y_int_list\n",
    "    def fit_batch(self,X,Y):\n",
    "        out = X\n",
    "        Y_, Y_int_list = self.forward(X)\n",
    "        print(Y_,'\\n',Y)\n",
    "        L,D = self.loss(Y_,Y)\n",
    "        for Y_int, layer in zip(Y_int_list[::-1],self.computational_graph[::-1]):\n",
    "            print(layer)\n",
    "            D = layer.backward(D,Y_int)\n",
    "\n",
    "            if layer.parametres is not None:\n",
    "                layer.update(self.optimizer)\n",
    "        return L \n",
    "    def fit(self, X,Y,epochs, bs):\n",
    "        losses = []\n",
    "        pbar = pkbar.Pbar(name='Training....', target= epochs)\n",
    "        kbar = pkbar.Kbar(target=epochs)\n",
    "        for epoch in range(epochs):\n",
    "            loss = 0.0 \n",
    "            for i in range(0,len(X),bs):\n",
    "                loss += self.fit_batch(X[i:i+bs],Y[i:i+bs])\n",
    "            losses.append(loss)\n",
    "            kbar.update(epoch+1, values=[(\"loss\",loss)])\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(y_pred,y_true):\n",
    "    loss = (y_true*np.log(y_pred))\n",
    "    print(len(y_pred))\n",
    "    return -np.sum(loss)/len(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "[[0.37826165]\n",
      " [0.30580289]\n",
      " [0.26832181]\n",
      " [0.24180999]] \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lain/Documents/Codes/ML & AI/scratchpad/ann.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39madd(Sigmoid())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mcompiler(cce_loss, SGD(lr\u001b[39m=\u001b[39m\u001b[39m5e-1\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m losses \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X,Y, epochs\u001b[39m=\u001b[39;49mEPOCHS, bs \u001b[39m=\u001b[39;49m X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m),losses)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mBCE\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/lain/Documents/Codes/ML & AI/scratchpad/ann.ipynb Cell 7\u001b[0m in \u001b[0;36mModel.fit\u001b[0;34m(self, X, Y, epochs, bs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(X),bs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_batch(X[i:i\u001b[39m+\u001b[39;49mbs],Y[i:i\u001b[39m+\u001b[39;49mbs])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m kbar\u001b[39m.\u001b[39mupdate(epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, values\u001b[39m=\u001b[39m[(\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m,loss)])\n",
      "\u001b[1;32m/home/lain/Documents/Codes/ML & AI/scratchpad/ann.ipynb Cell 7\u001b[0m in \u001b[0;36mModel.fit_batch\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Y_, Y_int_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(Y_,\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,Y)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m L,D \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(Y_,Y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m Y_int, layer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(Y_int_list[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomputational_graph[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lain/Documents/Codes/ML%20%26%20AI/scratchpad/ann.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m(layer)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]],dtype=float)\n",
    "Y = np.array([[0],[1],[1],[0]],dtype=float)\n",
    "\n",
    "\n",
    "EPOCHS = 10000\n",
    "\n",
    "model = Model()\n",
    "model.add(Linear(2,10))\n",
    "model.add(Sigmoid())\n",
    "\n",
    "model.add(Linear(10,1))\n",
    "model.add(Sigmoid())\n",
    "\n",
    "\n",
    "model.compiler(bce_loss, SGD(lr=5e-1))\n",
    "losses = model.fit(X,Y, epochs=EPOCHS, bs = X.shape[0])\n",
    "plt.plot(range(1, EPOCHS+1),losses)\n",
    "plt.ylabel('BCE')\n",
    "plt.xlabel('Number of epochs')\n",
    "\n",
    "plt.show()\n",
    "print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
